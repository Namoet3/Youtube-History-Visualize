{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef551a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "df = pd.read_json('watch_history31.json')\n",
    "print(df.columns)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd34a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "df = pd.read_json('watch_history31.json')\n",
    "print(\"After loading data:\")\n",
    "print(df.head())\n",
    "\n",
    "columns_to_drop = ['header', 'products', 'activityControls']\n",
    "for col in columns_to_drop:\n",
    "    if col not in df.columns:\n",
    "        print(f\"Column {col} does not exist in DataFrame\")\n",
    "\n",
    "df = df.drop(columns_to_drop, axis=1, errors='ignore')  \n",
    "print(\"After dropping columns:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2f993b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['description', 'details'],axis=1)\n",
    "df['time']=df['time'].apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8da55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#month_mapping = {\n",
    "#    'Oca': 'Jan', 'Şub': 'Feb', 'Mar': 'Mar', 'Nis': 'Apr',\n",
    "#    'May': 'May', 'Haz': 'Jun', 'Tem': 'Jul', 'Ağu': 'Aug',\n",
    "#    'Eyl': 'Sep', 'Eki': 'Oct', 'Kas': 'Nov', 'Ara': 'Dec'\n",
    "#}\n",
    "#df_date['Watched Date Time'] = pd.to_datetime(df_dates['Watched Date Time'].str[:-4], format='%d %b %Y %H:%M:%S', errors='coerce')\n",
    "#df_dates['Watched Date Time'] = hist_tree['Watched Date Time'].replace(month_mapping, regex=True)\n",
    "#Divide into year, month, day, hour, min, sec, etc.\n",
    "df['year'] = df['time'].dt.year\n",
    "df['month'] = df['time'].dt.month\n",
    "df['day'] = df['time'].dt.day\n",
    "df['hour'] = df['time'].dt.strftime('%H:00')\n",
    "df['minute'] = df['time'].dt.minute\n",
    "df['second'] = df['time'].dt.second\n",
    "df['dayname'] = df['time'].dt.day_name()\n",
    "df['weekend'] = df['time'].dt.day_name().isin(['Saturday','Sunday'])\n",
    "df = df.dropna().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34016c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'subtitles' in df.columns:\n",
    "    split_df = df.subtitles.astype(str).str.split(\",\", regex=True, expand=True)\n",
    "    if split_df.shape[1] > 0:  # Check if at least one column is created\n",
    "        df['subtitles'] = split_df[0]\n",
    "    else:\n",
    "        \n",
    "        df['subtitles'] = np.nan  # Example: setting NaN\n",
    "else:\n",
    "    \n",
    "    print(\"'subtitles' column not found in DataFrame\")\n",
    "df.subtitles.astype(str).str.removeprefix(\"[{'name': \")\n",
    "df.subtitles = df.subtitles.astype(str).str.removeprefix(\"[{'name': \")\n",
    "df.subtitles = df.subtitles.astype(str).str.removeprefix(\"'\").str.removeprefix('\"')\n",
    "df.subtitles = df.subtitles.astype(str).str.removesuffix(\"'\").str.removesuffix('\"')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07cb632",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'title':'Video Title', 'titleUrl':'Video URL', 'subtitles':'Youtube Channel'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c5d7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Count occurrences of each YouTube channel and get the top 5\n",
    "channel_counts = df['Youtube Channel'].value_counts().head(5)\n",
    "\n",
    "# Plot the data using a horizontal bar chart\n",
    "plt.figure(figsize=(10, 5))\n",
    "ax = sns.barplot(x=channel_counts, y=channel_counts.index, palette='viridis')\n",
    "\n",
    "# Set the labels and title of the plot\n",
    "ax.set(ylabel='Youtube Channel', xlabel='Watch Count', title='Top 5 Most Watched Youtube Channels in total')\n",
    "\n",
    "# Add the count labels on the bars\n",
    "ax.bar_label(ax.containers[0])\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4124a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = df['time'].dt.year\n",
    "def plot_top_channels_per_year(df, year):\n",
    "    # Filter the DataFrame for the given year\n",
    "    df_year = df[df['year'] == year]\n",
    "    \n",
    "    # Count occurrences of each YouTube channel for the year and get the top 5\n",
    "    channel_counts = df_year['Youtube Channel'].value_counts().head(5)\n",
    "\n",
    "    # Plot the data using a horizontal bar chart\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    ax = sns.barplot(x=channel_counts, y=channel_counts.index, palette='viridis')\n",
    "\n",
    "    # Set the labels and title of the plot\n",
    "    ax.set(ylabel='Youtube Channel', xlabel='Watch Count', title=f'Top 5 Most Watched Youtube Channels in {year}')\n",
    "\n",
    "    # Add the count labels on the bars\n",
    "    ax.bar_label(ax.containers[0])\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "for year in df['year'].unique():\n",
    "    plot_top_channels_per_year(df, year)\n",
    "# Creating a DataFrame to store channel watch counts per year\n",
    "channel_watch_counts = pd.DataFrame()\n",
    "\n",
    "for year in df['year'].unique():\n",
    "    yearly_data = df[df['year'] == year]['Youtube Channel'].value_counts().head(5)\n",
    "    channel_watch_counts = pd.concat([channel_watch_counts, yearly_data], axis=1)\n",
    "\n",
    "channel_watch_counts.columns = df['year'].unique()\n",
    "\n",
    "# Plotting the data\n",
    "channel_watch_counts.plot(kind='bar', figsize=(12, 10), title='Yearly Comparison of Top 5 Most Watched Youtube Channels')\n",
    "\n",
    "# Adding labels and legend\n",
    "plt.xlabel('Youtube Channel')\n",
    "plt.ylabel('Watch Count')\n",
    "plt.legend(title='Year')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78035bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_channels = df['Youtube Channel'].value_counts().head(10).index\n",
    "# Initialize a DataFrame to hold the watch counts\n",
    "channel_watch_counts = pd.DataFrame()\n",
    "\n",
    "# Iterate over each year\n",
    "for year in df['year'].unique():\n",
    "    # Filter the DataFrame for the specific year and top channels\n",
    "    df_year = df[(df['year'] == year) & (df['Youtube Channel'].isin(top_10_channels))]\n",
    "    \n",
    "    # Count occurrences for the year and align with top channels\n",
    "    yearly_counts = df_year['Youtube Channel'].value_counts().reindex(top_10_channels, fill_value=0)\n",
    "    \n",
    "    # Add this as a column to the channel_watch_counts DataFrame\n",
    "    channel_watch_counts[year] = yearly_counts\n",
    "\n",
    "# Transpose the DataFrame for plotting\n",
    "channel_watch_counts = channel_watch_counts.T\n",
    "# Plotting the data\n",
    "channel_watch_counts.plot(kind='bar', figsize=(15, 8), title='Yearly Comparison of Top 10 Most Watched Youtube Channels')\n",
    "\n",
    "# Define the width of the bars\n",
    "bar_width = 0.7\n",
    "\n",
    "# Get the number of groups and the total number of bars per group\n",
    "n_groups = len(channel_watch_counts.index)\n",
    "total_bars = len(channel_watch_counts.columns)\n",
    "\n",
    "# Calculate the width of each bar\n",
    "individual_bar_width = bar_width / total_bars\n",
    "\n",
    "# Plotting the data with wider bars\n",
    "#fig, ax = plt.subplots(figsize=(15, 8))\n",
    "for i, channel in enumerate(channel_watch_counts.columns):\n",
    "    ax.bar(np.arange(n_groups) + i * individual_bar_width, channel_watch_counts[channel], \n",
    "           width=individual_bar_width, label=channel)\n",
    "\n",
    "# Adding labels and title\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Watch Count')\n",
    "ax.set_title('Yearly Comparison of Top 10 Most Watched Youtube Channels')\n",
    "ax.set_xticks(np.arange(n_groups) + bar_width / 2)\n",
    "ax.set_xticklabels(channel_watch_counts.index)\n",
    "ax.legend(title='Youtube Channel', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051ad8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame and 'time' is the column with timestamps\n",
    "df['month'] = df['time'].dt.month_name()  # Extract month name from the timestamp\n",
    "\n",
    "# Group by the new 'month' column and count the occurrences\n",
    "monthly_counts = df.groupby('month').size()\n",
    "\n",
    "# Sort the months in calendar order since groupby will sort them alphabetically by default\n",
    "month_order = ['January', 'February', 'March', 'April', 'May', 'June', 'July', \n",
    "               'August', 'September', 'October', 'November', 'December']\n",
    "monthly_counts = monthly_counts.reindex(month_order)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))  # Adjust the size of the plot as needed\n",
    "monthly_counts.plot(kind='bar', color='skyblue')  # You can choose your own color\n",
    "\n",
    "plt.title('Videos being watched by Month')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)  # Rotate x-ticks for better readability\n",
    "plt.tight_layout()  # Adjust layout so everything fits without overlapping\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780291b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming you have a DataFrame 'df' with columns 'dayname' and 'time'\n",
    "\n",
    "watch = pd.Categorical(df['dayname'], categories=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'], ordered=True)\n",
    "watch = df['dayname'].groupby(watch).count()\n",
    "\n",
    "# Iterate through years\n",
    "for year in range(2019, 2025):\n",
    "    # Filter DataFrame for the specific year\n",
    "    df_year = df[df['time'].dt.year == year]\n",
    "\n",
    "    # Calculate the count of each day for the specific year\n",
    "    watch_year = pd.Categorical(df_year['dayname'], categories=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'], ordered=True)\n",
    "    watch_year = df_year['dayname'].groupby(watch_year).count()\n",
    "\n",
    "    plt.figure(figsize=(16, 7))\n",
    "    ax = sns.barplot(y=watch_year, x=watch_year.index)\n",
    "    ax.set(ylabel='Count', title=f'Videos being watched through a week in {year}')\n",
    "    ax.bar_label(ax.containers[0])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d19ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a DataFrame to hold the counts\n",
    "week_day_counts = pd.DataFrame()\n",
    "\n",
    "# Iterate over each year\n",
    "for year in range(2019, 2025):\n",
    "    # Filter the DataFrame for the specific year\n",
    "    df_year = df[df['time'].dt.year == year]\n",
    "    \n",
    "    # Calculate the count of each day for the specific year\n",
    "    watch_year = pd.Categorical(df_year['dayname'], categories=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'], ordered=True)\n",
    "    watch_year_count = df_year['dayname'].groupby(watch_year).count()\n",
    "    \n",
    "    # Add this as a column to the week_day_counts DataFrame\n",
    "    week_day_counts[year] = watch_year_count\n",
    "\n",
    "# Transpose the DataFrame for plotting\n",
    "week_day_counts = week_day_counts.T\n",
    "# Plotting the data\n",
    "plt.figure(figsize=(16, 9))\n",
    "for day in week_day_counts.columns:\n",
    "    plt.plot(week_day_counts.index, week_day_counts[day], marker='o', label=day)\n",
    "\n",
    "# Adding labels, legend, and title\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Watch Count')\n",
    "plt.title('Comparison of Video Watch Count by Day of the Week (2019-2024)')\n",
    "plt.legend(title='Day of the Week')\n",
    "plt.xticks(range(2019, 2025))\n",
    "plt.grid(True)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3f868d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b385c368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "# Load data\n",
    "df = pd.read_json('watch_history31.json')\n",
    "\n",
    "# Ensure 'time' is a datetime column\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "\n",
    "# Define your stopwords\n",
    "my_stopwords = set(STOPWORDS)\n",
    "additional_stopwords = {'izlediniz', 'shorts', 'videoyu', 'adlı', 'ile', 'bir', 'bu', 've', 'en', '<', '>', 'youtube', 'https', 'watch', 'v', 'izlendi', 'kaldırılan', 'video', 'vs'}\n",
    "my_stopwords.update(additional_stopwords)\n",
    "\n",
    "# Loop through each year and create a word cloud\n",
    "for year in range(2019, 2025):\n",
    "    # Filter DataFrame for the specific year\n",
    "    df_year = df[df['time'].dt.year == year]\n",
    "\n",
    "    # Combine all titles into one large string for that year\n",
    "    all_titles_year = ' '.join(df_year['title'].dropna())\n",
    "\n",
    "    # Check if there are titles available for the year\n",
    "    if all_titles_year:\n",
    "        # Create the word cloud object with your custom stopwords\n",
    "        wordcloud = WordCloud(width=800, height=400, background_color='white', stopwords=my_stopwords).generate(all_titles_year)\n",
    "\n",
    "        # Display the word cloud using matplotlib\n",
    "        plt.figure(figsize=(15, 7.5))\n",
    "        plt.imshow(wordcloud, interpolation='bilinear')\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Word Cloud for Video Titles in {year}')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"No titles available for the year {year}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ee65e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hour'] = df['time'].dt.hour  \n",
    "df['hour_minute'] = df['time'].dt.strftime('%H:%M')\n",
    "hourly_counts = df.groupby('hour').size()  \n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(hourly_counts.index, hourly_counts.values, marker='o')  \n",
    "plt.title('Videos being watched based on Hour')\n",
    "plt.xlabel('hour')\n",
    "plt.ylabel('count')\n",
    "plt.xticks(range(0, 24))  \n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7837a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time'] = pd.to_datetime(df['time'])\n",
    "\n",
    "# Filter the DataFrame for the years 2023 to 2024\n",
    "df_filtered = df[(df['time'].dt.year >= 2023) & (df['time'].dt.year <= 2024)]\n",
    "\n",
    "# Titles to exclude (replace with actual titles you want to exclude)\n",
    "titles_to_exclude = ['Kaldırılan bir video izlendi', 'Anket sorusu yanıtlandı', 'Title 3']  # Update this list\n",
    "\n",
    "# Filter out the titles to exclude\n",
    "df_filtered = df_filtered[~df_filtered['title'].isin(titles_to_exclude)]\n",
    "\n",
    "# Group by title and count the number of watches\n",
    "most_watch = df_filtered['title'].groupby(df_filtered['title']).count()\n",
    "most_watch = most_watch.sort_values(ascending=False).head(5)  # Top 3 most watched\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(15, 5))\n",
    "ax = sns.barplot(x=most_watch, y=most_watch.index)\n",
    "ax.set(ylabel='Video Title', xlabel='Watched (count)', title='Top 5 Most Watched Youtube Videos (2023-2024)')\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dbb62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure 'time' is a datetime column\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "\n",
    "# Create a 'weekend' column: True if the day is a weekend, False otherwise\n",
    "df['weekend'] = df['time'].dt.day_name().isin(['Saturday', 'Sunday'])\n",
    "\n",
    "# Count the number of views on weekends and weekdays\n",
    "sum_weekend = df['weekend'].sum()  # Count True values for weekend\n",
    "sum_weekday = df.shape[0] - sum_weekend  # Subtract weekend count from total to get weekday count\n",
    "\n",
    "# Values for the pie chart\n",
    "pie_values = [sum_weekday, sum_weekend]\n",
    "pie_labels = ['Weekday', 'Weekend']\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.title('Watching videos comparing Weekday and Weekend?')\n",
    "plt.pie(pie_values, labels=pie_labels, autopct='%1.2f%%', startangle=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ce095b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'time' is a datetime column in your DataFrame\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "\n",
    "# Extract hour and day of the week\n",
    "df['hour'] = df['time'].dt.hour\n",
    "df['dayname'] = df['time'].dt.day_name()\n",
    "\n",
    "# Order the days of the week\n",
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "df['dayname'] = pd.Categorical(df['dayname'], categories=day_order, ordered=True)\n",
    "\n",
    "# Group by 'hour' and 'dayname' and count the number of videos watched\n",
    "hour_dayname_count = df.groupby(['hour', 'dayname']).size().unstack(fill_value=0)\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(hour_dayname_count, cmap='cubehelix', linewidths=.5)\n",
    "plt.title('YouTube Watching Pattern by Time and Day of the Week')\n",
    "plt.ylabel('Hour of the Day')\n",
    "plt.xlabel('Day of the Week')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa6ae7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google_auth_oauthlib.flow\n",
    "import googleapiclient.discovery\n",
    "import googleapiclient.errors\n",
    "import pandas as pd\n",
    "\n",
    "scopes = [\"https://www.googleapis.com/auth/youtube.readonly\"]\n",
    "\n",
    "def main():\n",
    "    os.environ[\"OAUTHLIB_INSECURE_TRANSPORT\"] = \"1\"\n",
    "\n",
    "    api_service_name = \"youtube\"\n",
    "    api_version = \"v3\"\n",
    "    client_secrets_file = \"CLIENT_SECRET_FILE.json\"\n",
    "\n",
    "    # Get credentials and create an API client\n",
    "    flow = google_auth_oauthlib.flow.InstalledAppFlow.from_client_secrets_file(\n",
    "        client_secrets_file, scopes)\n",
    "    \n",
    "    # Use a local server for the OAuth flow\n",
    "    credentials = flow.run_local_server(port=0)\n",
    "\n",
    "    youtube = googleapiclient.discovery.build(\n",
    "        api_service_name, api_version, credentials=credentials)\n",
    "\n",
    "    # Fetch watched videos with a maximum of 400 results\n",
    "    max_results = 3000\n",
    "    next_page_token = None\n",
    "    video_data = []\n",
    "    \n",
    "    while max_results > 0:\n",
    "        watched_videos_request = youtube.videos().list(\n",
    "            part=\"snippet,contentDetails\",\n",
    "            myRating=\"like\",\n",
    "            maxResults=min(50, max_results),  # Fetch up to 50 videos at a time\n",
    "            pageToken=next_page_token\n",
    "        )\n",
    "        watched_videos_response = watched_videos_request.execute()\n",
    "\n",
    "        # Extract video IDs and category IDs\n",
    "        for item in watched_videos_response.get(\"items\", []):\n",
    "            video_id = item[\"id\"]\n",
    "            category_id = item[\"snippet\"][\"categoryId\"]\n",
    "            video_data.append({\"video_id\": video_id, \"category_id\": category_id})\n",
    "\n",
    "        # Check if there are more results\n",
    "        next_page_token = watched_videos_response.get(\"nextPageToken\")\n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "        max_results -= 25\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df_videos = pd.DataFrame(video_data)\n",
    "\n",
    "    # Fetch category names\n",
    "    category_names = {}\n",
    "    for category_id in df_videos['category_id'].unique():\n",
    "        category_request = youtube.videoCategories().list(\n",
    "            part=\"snippet\",\n",
    "            id=category_id\n",
    "        )\n",
    "        category_response = category_request.execute()\n",
    "\n",
    "        category_name = category_response[\"items\"][0][\"snippet\"][\"title\"]\n",
    "        category_names[category_id] = category_name\n",
    "\n",
    "    # Map category IDs to names\n",
    "    df_videos['category_name'] = df_videos['category_id'].map(category_names)\n",
    "\n",
    "    # Count the occurrences of each category\n",
    "    category_counts = df_videos['category_name'].value_counts()\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=category_counts.values, y=category_counts.index)\n",
    "    plt.xlabel('Number of Videos Watched')\n",
    "    plt.ylabel('Category')\n",
    "    plt.title('Most Watched YouTube Categories')\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9643bcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google_auth_oauthlib.flow\n",
    "import googleapiclient.discovery\n",
    "import googleapiclient.errors\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "scopes = [\"https://www.googleapis.com/auth/youtube.readonly\"]\n",
    "\n",
    "def main():\n",
    "    os.environ[\"OAUTHLIB_INSECURE_TRANSPORT\"] = \"1\"\n",
    "\n",
    "    api_service_name = \"youtube\"\n",
    "    api_version = \"v3\"\n",
    "    client_secrets_file = \"CLIENT_SECRET_FILE.json\"\n",
    "\n",
    "    # Get credentials and create an API client\n",
    "    flow = google_auth_oauthlib.flow.InstalledAppFlow.from_client_secrets_file(\n",
    "        client_secrets_file, scopes)\n",
    "    \n",
    "    # Use a local server for the OAuth flow\n",
    "    credentials = flow.run_local_server(port=0)\n",
    "\n",
    "    youtube = googleapiclient.discovery.build(\n",
    "        api_service_name, api_version, credentials=credentials)\n",
    "\n",
    "    # Fetch liked videos\n",
    "    liked_videos = []\n",
    "    next_page_token = None\n",
    "    \n",
    "    while True:\n",
    "        liked_videos_request = youtube.videos().list(\n",
    "            part=\"snippet\",\n",
    "            myRating=\"like\",\n",
    "            maxResults=25,  # Fetch up to 50 liked videos at a time\n",
    "            pageToken=next_page_token\n",
    "        )\n",
    "        liked_videos_response = liked_videos_request.execute()\n",
    "\n",
    "        # Extract liked videos and their channels\n",
    "        for item in liked_videos_response.get(\"items\", []):\n",
    "            snippet = item[\"snippet\"]\n",
    "            video_id = item[\"id\"]\n",
    "            channel_title = snippet[\"channelTitle\"]\n",
    "            \n",
    "            liked_videos.append({\"video_id\": video_id, \"channel_title\": channel_title})\n",
    "\n",
    "        # Check if there are more results\n",
    "        next_page_token = liked_videos_response.get(\"nextPageToken\")\n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df_liked_videos = pd.DataFrame(liked_videos)\n",
    "\n",
    "    # Count the number of liked videos from each channel\n",
    "    channel_like_counts = df_liked_videos['channel_title'].value_counts()\n",
    "\n",
    "    # Select the top N channels with the most liked videos for the bar chart\n",
    "    top_channels = channel_like_counts.head(10)  # You can adjust the number of channels to display\n",
    "\n",
    "    # Plot the bar chart\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    top_channels.plot(kind='bar', color='skyblue')\n",
    "    plt.xlabel(\"Channel\")\n",
    "    plt.ylabel(\"Number of Liked Videos\")\n",
    "    plt.title(\"Top Channels with the Most Liked Videos\")\n",
    "    plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better visibility\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb780b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google_auth_oauthlib.flow\n",
    "import googleapiclient.discovery\n",
    "import googleapiclient.errors\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up YouTube API credentials and authenticate\n",
    "scopes = [\"https://www.googleapis.com/auth/youtube.readonly\"]\n",
    "os.environ[\"OAUTHLIB_INSECURE_TRANSPORT\"] = \"1\"\n",
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\"\n",
    "client_secrets_file = \"CLIENT_SECRET_FILE.json\"  # Replace with your client secrets file\n",
    "\n",
    "flow = google_auth_oauthlib.flow.InstalledAppFlow.from_client_secrets_file(\n",
    "    client_secrets_file, scopes)\n",
    "credentials = flow.run_local_server(port=0)\n",
    "youtube = googleapiclient.discovery.build(api_service_name, api_version, credentials=credentials)\n",
    "\n",
    "# Fetch liked videos with a maximum of 500\n",
    "max_results = 500\n",
    "liked_videos = []\n",
    "next_page_token = None\n",
    "while len(liked_videos) < max_results:\n",
    "    liked_videos_request = youtube.videos().list(\n",
    "        part=\"snippet\",\n",
    "        myRating=\"like\",\n",
    "        maxResults=min(50, max_results - len(liked_videos)),  # Fetch up to 50 liked videos at a time\n",
    "        pageToken=next_page_token\n",
    "    )\n",
    "    liked_videos_response = liked_videos_request.execute()\n",
    "    liked_videos.extend(liked_videos_response.get(\"items\", []))\n",
    "\n",
    "    next_page_token = liked_videos_response.get(\"nextPageToken\")\n",
    "    if not next_page_token or len(liked_videos) >= max_results:\n",
    "        break\n",
    "\n",
    "# Extract category information and count occurrences\n",
    "category_counts = {}\n",
    "for video in liked_videos:\n",
    "    category_id = video[\"snippet\"][\"categoryId\"]\n",
    "    \n",
    "    # Fetch category name using the category ID\n",
    "    category_request = youtube.videoCategories().list(\n",
    "        part=\"snippet\",\n",
    "        id=category_id\n",
    "    )\n",
    "    category_response = category_request.execute()\n",
    "    \n",
    "    # Extract category name\n",
    "    category_name = category_response[\"items\"][0][\"snippet\"][\"title\"]\n",
    "    \n",
    "    # Count occurrences of each category\n",
    "    if category_name in category_counts:\n",
    "        category_counts[category_name] += 1\n",
    "    else:\n",
    "        category_counts[category_name] = 1\n",
    "\n",
    "# Sort the categories by count\n",
    "sorted_categories = sorted(category_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Extract category names and counts for the histogram\n",
    "categories = [category[0] for category in sorted_categories]\n",
    "counts = [category[1] for category in sorted_categories]\n",
    "\n",
    "# Create a histogram chart\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(categories, counts)\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Liked Count')\n",
    "plt.title('Most Liked YouTube Categories ()')\n",
    "plt.xticks(rotation=90)  # Rotate category labels for better readability\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the histogram chart\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c941ff58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c8d313",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
